{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnKV7+H7/r/OnO3u1n/SvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singlaG554/Mini-projects/blob/main/Google_image_downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWYhVz0W0Rm5",
        "outputId": "51b7772d-f315-4bc4-b274-118963433f13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.13.4)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from icrawler) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2025.6.15)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncLS-Xw30FjK",
        "outputId": "10baca96-dfa6-4345-ff7c-095eb4e6f934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the search keyword: cycle\n",
            "Enter the number of images to download: 10\n",
            "\n",
            "üîç Downloading 10 images for 'cycle'...\n",
            "\n",
            "‚úÖ Images downloaded and zipped successfully.\n",
            "ZIP file saved at: cycle_images.zip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "def download_images(keyword, num_images, download_dir='images'):\n",
        "    # Create download directory if not exists\n",
        "    if not os.path.exists(download_dir):\n",
        "        os.makedirs(download_dir)\n",
        "\n",
        "    # Initialize crawler\n",
        "    crawler = GoogleImageCrawler(storage={'root_dir': download_dir})\n",
        "    crawler.crawl(keyword=keyword, max_num=num_images)\n",
        "\n",
        "    return download_dir\n",
        "\n",
        "def zip_images(folder_path, zip_name):\n",
        "    zip_path = zip_name if zip_name.endswith('.zip') else zip_name + '.zip'\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), arcname=file)\n",
        "    return zip_path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    keyword = input(\"Enter the search keyword: \")\n",
        "    num_images = int(input(\"Enter the number of images to download: \"))\n",
        "\n",
        "    download_folder = f\"downloads_{keyword.replace(' ', '_')}\"\n",
        "    print(f\"\\nüîç Downloading {num_images} images for '{keyword}'...\")\n",
        "\n",
        "    download_images(keyword, num_images, download_folder)\n",
        "\n",
        "    zip_file_name = f\"{keyword.replace(' ', '_')}_images.zip\"\n",
        "    zip_path = zip_images(download_folder, zip_file_name)\n",
        "\n",
        "    print(f\"\\n‚úÖ Images downloaded and zipped successfully.\")\n",
        "    print(f\"ZIP file saved at: {zip_path}\")\n"
      ]
    }
  ]
}